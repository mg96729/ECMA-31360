#Now get formulas for SUR
list_fo = list()
for (x in list_survivors){
xname = toString(x)
fo <- as.formula(paste(xname, "~treat"))
list_fo <- append(list_fo, fo)
}
#Now use SUR estimation on this list of formulas
sur_fit <- systemfit::systemfit(formula = list_fo, data=df, method="SUR")
#Print summary
print(paste('stratum:', s))
print(summary(sur_fit)$coefficients)
rm(sur_fit)
}
}
#First, we assign the weights and difference in CATT (?) in one loop
w = list()
d = list()
for(s in 1:10){
#set df to this stratum
df <- psid_trimmed[psid_trimmed$stratum == s]
#if treated AND control counts positive:
if(nrow(df[df$treat==1]) >0
& nrow(df[df$treat==0])>0
){
#num of treated in each strata
n <- nrow(df[df$treat == 1])
w <- c(w, n)
#Find avg treatment effect in stratum
avg_t <- mean(df[df$treat == 1]$re78)
avg_c <- mean(df[df$treat == 0]$re78)
diff <- avg_t-avg_c
d <- append(d, c(diff))
}
}
#make appended list "normal"
d <- unlist(d)
w <- unlist(w)
#normalize weight
w <- w/sum(w)
#Now for the estimator:
att <- weighted.mean(d, w)
att
X <- psid_trimmed$p_logit
Tr<- psid_trimmed$treat
Y <- psid_trimmed$re78
install_packages_if_needed(c("Matching"))
rr  <- Matching::Match(Y=Y, Tr=Tr, X=X, M=1, estimand='ATT');
summary(rr)
source("./Functions.R")
install_packages_if_needed(c("utils"))
library(tidyr)
#Import the csv files
dt_psid <- data.table::as.data.table(utils::read.delim(file = "nswpsid.csv",
sep = ","))
#mutate the data table to add additional variables:
dt_psid <-dt_psid %>%
dplyr::mutate(.data=dt_psid,
agesq = age**2,
edusq = edu**2,
re74sq = re74**2,
re75sq = re75**2,
u74black = u74*black)
#Write the formula (as in Pset 5):
pscore_formula <- as.formula("treat ~ age + agesq +edu + edusq + married + nodegree + black + hisp + re74 + re75 + re74sq + re75sq + u74black")
#mle estimation
mle <- stats::glm(pscore_formula, family = binomial( ), data = dt_psid)
#prediction
p_logit <- stats::predict(mle, type = "response")
#Store in dt
dt_psid <-dt_psid %>%
dplyr::mutate(.data=dt_psid,
p_logit = p_logit)
summary(p_logit)
#This gives the summary of the p-scores of the control and treatment groups:
dt_psid %>%
dplyr::group_by(treat) %>%
dplyr::summarise_at(.var=c('p_logit'), .funs = c(max = max, min=min))
#Now find the common support in treat and control groups:
upper_p <- min(by(data = dt_psid$p_logit, INDICES = dt_psid$treat, FUN = max))
lower_p <- max(by(data = dt_psid$p_logit, INDICES = dt_psid$treat, FUN = min))
#Now we trim the data set using these bounds:
psid_trimmed <- dplyr::filter(.data = dt_psid, p_logit >= lower_p & p_logit <= upper_p)
# Draw scatter plot of post-intervention earnings and the Logit-based pscore, by group;
# overlay smooth local regression line.
plot_df <- psid_trimmed %>%
dplyr::filter(re78 < 20000) %>% # drop outliers for plotting purposes
dplyr::mutate(treat = factor(ifelse(treat == 1, "Treated", "Control"))) #labels?
p <- ggplot2::ggplot(plot_df, ggplot2::aes(x = p_logit, y = re78)) +
ggplot2::facet_grid(~treat) + #plot 2 graphs for treat and control
ggplot2::geom_point() + #scatterplot
ggplot2::scale_y_continuous(breaks=seq(0,20000,by=1000)) + #?
ggplot2::geom_smooth(method = "loess", formula = y ~ x, span = 2,
method.args = list(degree = 1)) +
#what is span of 0.5? is it of x?
ggplot2::ylab("Real Earnings in 1978") +
ggplot2::xlab("Estimated Propensity Score") +
ggplot2::labs(caption = "Data Source: NSW-PSID1.") + ggplot2::theme_bw()
p
# Save plot object to PDF file
# ggplot2::ggsave(filename_plot_2, plot = p)
# the save function is not working: it says cannot find target with the name "filename_plot_2"
#First, set the bin bounds
b <- c(0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1)
# Calling .bincode() function
psid_trimmed <- psid_trimmed %>%
dplyr::mutate(.data = psid_trimmed,
stratum = .bincode(p_logit, b, TRUE, TRUE))
# Now we gives a summary, grouped by variable stratum:
psid_trimmed %>%
dplyr::group_by(stratum) %>%
dplyr::summarize(
'count of treated units' = sum(treat == 1),
'count of control units' = sum(treat == 0),
'max p-score' = max(p_logit),
'min p-score' = min(p_logit)
)
# Declare a function that identifies perfectly collinear covariates.
# Note: this fnc is roughly equivalent to _rmcoll in STATA.
rmcoll <- function(df, colnames = names(df)) {
# Arguments:
# - df: A data frame.
# - colnames: A list of column names.
# Returns:
# A list with the column names of collinear variables.
df_ <- df %>% dplyr::select(one_of(colnames))
cc <- coef(lm(rep(1, nrow(df_)) ~ ., data = df_))
return(names(cc)[is.na(cc)])
} # end fnc rmcoll
#listing OPVs
list_OPVs <- c('age', 'edu', 'married', 'black', 'hisp', 're74', 're75', 'u74black')
#Now for each strata 1-10:
for(s in 1:10){
#set df to this stratum
df <- psid_trimmed[psid_trimmed$stratum == s]
#if treated AND control counts positive:
if(nrow(df[df$treat==1]) >0
& nrow(df[df$treat==0])>0
){
#get rid of colinear terms
to_die <- rmcoll(df = df)
list_survivors <- list_OPVs[!(list_OPVs %in% to_die)]
#Now get formulas for SUR
list_fo = list()
for (x in list_survivors){
xname = toString(x)
fo <- as.formula(paste(xname, "~treat"))
list_fo <- append(list_fo, fo)
}
#Now use SUR estimation on this list of formulas
sur_fit <- systemfit::systemfit(formula = list_fo, data=df, method="SUR")
#Print summary
print(paste('stratum:', s))
print(summary(sur_fit)$coefficients)
rm(sur_fit)
}
}
#First, we assign the weights and difference in CATT (?) in one loop
w = list()
d = list()
for(s in 1:10){
#set df to this stratum
df <- psid_trimmed[psid_trimmed$stratum == s]
#if treated AND control counts positive:
if(nrow(df[df$treat==1]) >0
& nrow(df[df$treat==0])>0
){
#num of treated in each strata
n <- nrow(df[df$treat == 1])
w <- c(w, n)
#Find avg treatment effect in stratum
avg_t <- mean(df[df$treat == 1]$re78)
avg_c <- mean(df[df$treat == 0]$re78)
diff <- avg_t-avg_c
d <- append(d, c(diff))
}
}
#make appended list "normal"
d <- unlist(d)
w <- unlist(w)
#normalize weight
w <- w/sum(w)
#Now for the estimator:
att <- weighted.mean(d, w)
att
X <- psid_trimmed$p_logit
Tr<- psid_trimmed$treat
Y <- psid_trimmed$re78
install_packages_if_needed(c("Matching"))
rr  <- Matching::Match(Y=Y, Tr=Tr, X=X, M=1, estimand='ATT');
summary(rr)
source("./Functions.R")
install_packages_if_needed(c("utils"))
library(tidyr)
#Import the csv files
dt_psid <- data.table::as.data.table(utils::read.delim(file = "nswpsid.csv",
sep = ","))
#mutate the data table to add additional variables:
dt_psid <-dt_psid %>%
dplyr::mutate(.data=dt_psid,
agesq = age**2,
edusq = edu**2,
re74sq = re74**2,
re75sq = re75**2,
u74black = u74*black)
#Write the formula (as in Pset 5):
pscore_formula <- as.formula("treat ~ age + agesq +edu + edusq + married + nodegree + black + hisp + re74 + re75 + re74sq + re75sq + u74black")
#mle estimation
mle <- stats::glm(pscore_formula, family = binomial( ), data = dt_psid)
#prediction
p_logit <- stats::predict(mle, type = "response")
#Store in dt
dt_psid <-dt_psid %>%
dplyr::mutate(.data=dt_psid,
p_logit = p_logit)
summary(p_logit)
#This gives the summary of the p-scores of the control and treatment groups:
dt_psid %>%
dplyr::group_by(treat) %>%
dplyr::summarise_at(.var=c('p_logit'), .funs = c(max = max, min=min))
#Now find the common support in treat and control groups:
upper_p <- min(by(data = dt_psid$p_logit, INDICES = dt_psid$treat, FUN = max))
lower_p <- max(by(data = dt_psid$p_logit, INDICES = dt_psid$treat, FUN = min))
#Now we trim the data set using these bounds:
psid_trimmed <- dplyr::filter(.data = dt_psid, p_logit >= lower_p & p_logit <= upper_p)
# Draw scatter plot of post-intervention earnings and the Logit-based pscore, by group;
# overlay smooth local regression line.
plot_df <- psid_trimmed %>%
dplyr::filter(re78 < 20000) %>% # drop outliers for plotting purposes
dplyr::mutate(treat = factor(ifelse(treat == 1, "Treated", "Control"))) #labels?
p <- ggplot2::ggplot(plot_df, ggplot2::aes(x = p_logit, y = re78)) +
ggplot2::facet_grid(~treat) + #plot 2 graphs for treat and control
ggplot2::geom_point() + #scatterplot
ggplot2::scale_y_continuous(breaks=seq(0,20000,by=1000)) + #?
ggplot2::geom_smooth(method = "loess", formula = y ~ x, span = 2,
method.args = list(degree = 1)) +
#what is span of 0.5? is it of x?
ggplot2::ylab("Real Earnings in 1978") +
ggplot2::xlab("Estimated Propensity Score") +
ggplot2::labs(caption = "Data Source: NSW-PSID1.") + ggplot2::theme_bw()
p
# Save plot object to PDF file
# ggplot2::ggsave(filename_plot_2, plot = p)
# the save function is not working: it says cannot find target with the name "filename_plot_2"
#First, set the bin bounds
b <- c(0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1)
# Calling .bincode() function
psid_trimmed <- psid_trimmed %>%
dplyr::mutate(.data = psid_trimmed,
stratum = .bincode(p_logit, b, TRUE, TRUE))
# Now we gives a summary, grouped by variable stratum:
psid_trimmed %>%
dplyr::group_by(stratum) %>%
dplyr::summarize(
'count of treated units' = sum(treat == 1),
'count of control units' = sum(treat == 0),
'max p-score' = max(p_logit),
'min p-score' = min(p_logit)
)
# Declare a function that identifies perfectly collinear covariates.
# Note: this fnc is roughly equivalent to _rmcoll in STATA.
rmcoll <- function(df, colnames = names(df)) {
# Arguments:
# - df: A data frame.
# - colnames: A list of column names.
# Returns:
# A list with the column names of collinear variables.
df_ <- df %>% dplyr::select(one_of(colnames))
cc <- coef(lm(rep(1, nrow(df_)) ~ ., data = df_))
return(names(cc)[is.na(cc)])
} # end fnc rmcoll
#listing OPVs
list_OPVs <- c('age', 'edu', 'married', 'black', 'hisp', 're74', 're75', 'u74black')
#Now for each strata 1-10:
for(s in 1:10){
#set df to this stratum
df <- psid_trimmed[psid_trimmed$stratum == s]
#if treated AND control counts positive:
if(nrow(df[df$treat==1]) >0
& nrow(df[df$treat==0])>0
){
#get rid of colinear terms
to_die <- rmcoll(df = df)
list_survivors <- list_OPVs[!(list_OPVs %in% to_die)]
#Now get formulas for SUR
list_fo = list()
for (x in list_survivors){
xname = toString(x)
fo <- as.formula(paste(xname, "~treat"))
list_fo <- append(list_fo, fo)
}
#Now use SUR estimation on this list of formulas
sur_fit <- systemfit::systemfit(formula = list_fo, data=df, method="SUR")
#Print summary
print(paste('stratum:', s))
print(summary(sur_fit)$coefficients)
rm(sur_fit)
}
}
#First, we assign the weights and difference in CATT (?) in one loop
w = list()
d = list()
for(s in 1:10){
#set df to this stratum
df <- psid_trimmed[psid_trimmed$stratum == s]
#if treated AND control counts positive:
if(nrow(df[df$treat==1]) >0
& nrow(df[df$treat==0])>0
){
#num of treated in each strata
n <- nrow(df[df$treat == 1])
w <- c(w, n)
#Find avg treatment effect in stratum
avg_t <- mean(df[df$treat == 1]$re78)
avg_c <- mean(df[df$treat == 0]$re78)
diff <- avg_t-avg_c
d <- append(d, c(diff))
}
}
#make appended list "normal"
d <- unlist(d)
w <- unlist(w)
#normalize weight
w <- w/sum(w)
#Now for the estimator:
att <- weighted.mean(d, w)
att
X <- psid_trimmed$p_logit
Tr<- psid_trimmed$treat
Y <- psid_trimmed$re78
install_packages_if_needed(c("Matching"))
rr  <- Matching::Match(Y=Y, Tr=Tr, X=X, M=1, estimand='ATT');
summary(rr)
dt_pairing <- data.table::data.table(
index_treated = rr$index.treated,
index_control = rr$index.control,
p_treated = psid_trimmed[rr$index.treated]$p_logit,
p_control = psid_trimmed[rr$index.control]$p_logit,
y_treated = psid_trimmed[rr$index.treated]$re78,
y_control = psid_trimmed[rr$index.control]$re78,
weight = rr$weights
)
# dt_pairing <-dt_pairing %>%
#   dplyr::mutate(.data=dt_pairing,
#
#                 )
source("./Functions.R")
install_packages_if_needed(c("utils"))
library(tidyr)
#Import the csv files
dt_psid <- data.table::as.data.table(utils::read.delim(file = "nswpsid.csv",
sep = ","))
#mutate the data table to add additional variables:
dt_psid <-dt_psid %>%
dplyr::mutate(.data=dt_psid,
agesq = age**2,
edusq = edu**2,
re74sq = re74**2,
re75sq = re75**2,
u74black = u74*black)
#Write the formula (as in Pset 5):
pscore_formula <- as.formula("treat ~ age + agesq +edu + edusq + married + nodegree + black + hisp + re74 + re75 + re74sq + re75sq + u74black")
#mle estimation
mle <- stats::glm(pscore_formula, family = binomial( ), data = dt_psid)
#prediction
p_logit <- stats::predict(mle, type = "response")
#Store in dt
dt_psid <-dt_psid %>%
dplyr::mutate(.data=dt_psid,
p_logit = p_logit)
summary(p_logit)
#This gives the summary of the p-scores of the control and treatment groups:
dt_psid %>%
dplyr::group_by(treat) %>%
dplyr::summarise_at(.var=c('p_logit'), .funs = c(max = max, min=min))
#Now find the common support in treat and control groups:
upper_p <- min(by(data = dt_psid$p_logit, INDICES = dt_psid$treat, FUN = max))
lower_p <- max(by(data = dt_psid$p_logit, INDICES = dt_psid$treat, FUN = min))
#Now we trim the data set using these bounds:
psid_trimmed <- dplyr::filter(.data = dt_psid, p_logit >= lower_p & p_logit <= upper_p)
# Draw scatter plot of post-intervention earnings and the Logit-based pscore, by group;
# overlay smooth local regression line.
plot_df <- psid_trimmed %>%
dplyr::filter(re78 < 20000) %>% # drop outliers for plotting purposes
dplyr::mutate(treat = factor(ifelse(treat == 1, "Treated", "Control"))) #labels?
p <- ggplot2::ggplot(plot_df, ggplot2::aes(x = p_logit, y = re78)) +
ggplot2::facet_grid(~treat) + #plot 2 graphs for treat and control
ggplot2::geom_point() + #scatterplot
ggplot2::scale_y_continuous(breaks=seq(0,20000,by=1000)) + #?
ggplot2::geom_smooth(method = "loess", formula = y ~ x, span = 2,
method.args = list(degree = 1)) +
#what is span of 0.5? is it of x?
ggplot2::ylab("Real Earnings in 1978") +
ggplot2::xlab("Estimated Propensity Score") +
ggplot2::labs(caption = "Data Source: NSW-PSID1.") + ggplot2::theme_bw()
p
# Save plot object to PDF file
# ggplot2::ggsave(filename_plot_2, plot = p)
# the save function is not working: it says cannot find target with the name "filename_plot_2"
#First, set the bin bounds
b <- c(0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1)
# Calling .bincode() function
psid_trimmed <- psid_trimmed %>%
dplyr::mutate(.data = psid_trimmed,
stratum = .bincode(p_logit, b, TRUE, TRUE))
# Now we gives a summary, grouped by variable stratum:
psid_trimmed %>%
dplyr::group_by(stratum) %>%
dplyr::summarize(
'count of treated units' = sum(treat == 1),
'count of control units' = sum(treat == 0),
'max p-score' = max(p_logit),
'min p-score' = min(p_logit)
)
# Declare a function that identifies perfectly collinear covariates.
# Note: this fnc is roughly equivalent to _rmcoll in STATA.
rmcoll <- function(df, colnames = names(df)) {
# Arguments:
# - df: A data frame.
# - colnames: A list of column names.
# Returns:
# A list with the column names of collinear variables.
df_ <- df %>% dplyr::select(one_of(colnames))
cc <- coef(lm(rep(1, nrow(df_)) ~ ., data = df_))
return(names(cc)[is.na(cc)])
} # end fnc rmcoll
#listing OPVs
list_OPVs <- c('age', 'edu', 'married', 'black', 'hisp', 're74', 're75', 'u74black')
#Now for each strata 1-10:
for(s in 1:10){
#set df to this stratum
df <- psid_trimmed[psid_trimmed$stratum == s]
#if treated AND control counts positive:
if(nrow(df[df$treat==1]) >0
& nrow(df[df$treat==0])>0
){
#get rid of colinear terms
to_die <- rmcoll(df = df)
list_survivors <- list_OPVs[!(list_OPVs %in% to_die)]
#Now get formulas for SUR
list_fo = list()
for (x in list_survivors){
xname = toString(x)
fo <- as.formula(paste(xname, "~treat"))
list_fo <- append(list_fo, fo)
}
#Now use SUR estimation on this list of formulas
sur_fit <- systemfit::systemfit(formula = list_fo, data=df, method="SUR")
#Print summary
print(paste('stratum:', s))
print(summary(sur_fit)$coefficients)
rm(sur_fit)
}
}
#First, we assign the weights and difference in CATT (?) in one loop
w = list()
d = list()
for(s in 1:10){
#set df to this stratum
df <- psid_trimmed[psid_trimmed$stratum == s]
#if treated AND control counts positive:
if(nrow(df[df$treat==1]) >0
& nrow(df[df$treat==0])>0
){
#num of treated in each strata
n <- nrow(df[df$treat == 1])
w <- c(w, n)
#Find avg treatment effect in stratum
avg_t <- mean(df[df$treat == 1]$re78)
avg_c <- mean(df[df$treat == 0]$re78)
diff <- avg_t-avg_c
d <- append(d, c(diff))
}
}
#make appended list "normal"
d <- unlist(d)
w <- unlist(w)
#normalize weight
w <- w/sum(w)
#Now for the estimator:
att <- weighted.mean(d, w)
att
X <- psid_trimmed$p_logit
Tr<- psid_trimmed$treat
Y <- psid_trimmed$re78
install_packages_if_needed(c("Matching"))
rr  <- Matching::Match(Y=Y, Tr=Tr, X=X, M=1, estimand='ATT');
summary(rr)
dt_pairing <- data.table::data.table(
index_treated = rr$index.treated,
index_control = rr$index.control,
p_treated = psid_trimmed[rr$index.treated]$p_logit,
p_control = psid_trimmed[rr$index.control]$p_logit,
y_treated = psid_trimmed[rr$index.treated]$re78,
y_control = psid_trimmed[rr$index.control]$re78,
weight = rr$weights
)
# dt_pairing <-dt_pairing %>%
#   dplyr::mutate(.data=dt_pairing,
#
#                 )
length(unique(dt_pairing$index_treated))
nrow(dt_pairing[dt_pairing$weight == 1])
length(unique(dt_pairing$index_control))/nrow(psid_trimmed[psid_trimmed$treat == 0, ])
length(unique(dt_pairing[dt_pairing$weight == 1]$index_control))
d <- mapply('-', dt_pairing$y_treated, dt_pairing$y_control, SIMPLIFY = FALSE)
sum(unlist(d)*dt_pairing$weight)/nrow(psid_trimmed[psid_trimmed$treat ==1])
rr2  <- Matching::Match(Y=Y, Tr=Tr, X=X, M=1, estimand='ATT', ties = FALSE);
summary(rr2)
nnm_balance <- Matching::MatchBalance(treat~age + edu + black +
hisp + married + nodegree + re74 + re75 +
u74 + u75, data=psid_trimmed, match.out=rr, nboots=500)
